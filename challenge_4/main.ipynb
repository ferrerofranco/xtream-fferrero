{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.config import Configurations\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logging_level = logging.INFO\n",
    "\n",
    "configs = Configurations()\n",
    "logging_filename = configs.get_log_file_name()\n",
    "logging_path = os.path.join('logs/',logging_filename)\n",
    "\n",
    "logging_format = \"%(asctime)s-%(levelname)s: %(message)s\"\n",
    "logging_formatter = logging.Formatter(logging_format)\n",
    "\n",
    "logger = logging.getLogger(configs.get_logger_name())\n",
    "logger.setLevel(logging_level)\n",
    "\n",
    "logging_file_handler = logging.handlers.RotatingFileHandler(logging_path,\n",
    "                                                            maxBytes=10485760,\n",
    "                                                            backupCount=5)\n",
    "logging_file_handler.setLevel(logging_level)\n",
    "logging_file_handler.setFormatter(logging_formatter)\n",
    "logger.addHandler(logging_file_handler)\n",
    "\n",
    "logging_stream_handler = logging.StreamHandler()\n",
    "logging_stream_handler.setLevel(logging_level)\n",
    "logging_stream_handler.setFormatter(logging_formatter)\n",
    "logger.addHandler(logging_stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today().strftime(\"%Y-%m-%d\")\n",
    "target_year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 20:59:06,585-INFO: [DatabaseDAO] Initializing database\n"
     ]
    }
   ],
   "source": [
    "from src.data_extractor import DataExtractor\n",
    "data_extractor = DataExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 20:59:42,603-INFO: [DataExtractor] Fetching and unifying data\n",
      "2024-01-17 20:59:42,632-INFO: [DataController] Fetching all files in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data\n",
      "2024-01-17 20:59:42,634-INFO: [DataController] Reading parquet 2019.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,001-INFO: [DataController] Reading parquet 2018.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,008-INFO: [DataController] Reading parquet 2015.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,014-INFO: [DataController] Reading parquet 2012.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,020-INFO: [DataController] Reading parquet 2007.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,026-INFO: [DataController] Reading parquet 2006.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,035-INFO: [DataController] Reading parquet 2013.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,044-INFO: [DataController] Reading parquet 2014.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,052-INFO: [DataController] Reading parquet 2016.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,067-INFO: [DataController] Reading parquet 2011.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,075-INFO: [DataController] Reading parquet 2010.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,082-INFO: [DataController] Reading parquet 2017.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,093-INFO: [DataController] Reading parquet 2008.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,101-INFO: [DataController] Reading parquet 2009.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/raw_data/None\n",
      "2024-01-17 20:59:46,109-INFO: [StorageDAO] Saving dataframe as /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/raw/2024-01-17_all_up_to_2019.parquet.gzip\n"
     ]
    }
   ],
   "source": [
    "data_extractor.extract_data(target_year,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 21:00:03,170-INFO: [DatabaseDAO] Initializing database\n"
     ]
    }
   ],
   "source": [
    "from src.data_enricher import DataEnricher\n",
    "data_enricher = DataEnricher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 21:00:19,211-INFO: [DataEnricher] Enriching data\n",
      "2024-01-17 21:00:19,213-INFO: [DataController] Reading parquet 2024-01-17_all_up_to_2019.parquet.gzip in /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/raw\n",
      "2024-01-17 21:00:19,378-INFO: [DataEnricher] Calculating covariates\n",
      "2024-01-17 21:00:32,516-INFO: [DataEnricher] Saving enriched data\n",
      "2024-01-17 21:00:32,517-INFO: [StorageDAO] Pickling file as /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/preprocessed/2024-01-17_y_scaler_2019\n",
      "2024-01-17 21:00:32,519-INFO: [StorageDAO] Pickling timeseries as /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/preprocessed/2024-01-17_y_train_scaled_2019\n",
      "2024-01-17 21:00:32,522-INFO: [StorageDAO] Pickling timeseries as /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/preprocessed/2024-01-17_y_val_2019\n",
      "2024-01-17 21:00:32,523-INFO: [StorageDAO] Pickling timeseries as /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/preprocessed/2024-01-17_covariates_scaled_2019\n"
     ]
    }
   ],
   "source": [
    "data_enricher.enrich_dataset(target_year,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoferrero/anaconda3/envs/xtream_main/lib/python3.9/site-packages/statsforecast/core.py:26: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2024-01-17 21:01:10,150-INFO: [DatabaseDAO] Initializing database\n"
     ]
    }
   ],
   "source": [
    "from src.model_trainer import ModelTrainer\n",
    "model_trainer = ModelTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 21:01:59,128-INFO: [DataController] Fetching all files for training\n",
      "2024-01-17 21:01:59,138-INFO: [StorageDAO] Loading pickle /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/preprocessed/2024-01-17_covariates_scaled_2019.pkl\n",
      "2024-01-17 21:01:59,144-INFO: [StorageDAO] Loading pickle /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/preprocessed/2024-01-17_y_scaler_2019.pkl\n",
      "2024-01-17 21:01:59,147-INFO: [StorageDAO] Loading pickle /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/preprocessed/2024-01-17_y_train_scaled_2019.pkl\n",
      "2024-01-17 21:01:59,152-INFO: [StorageDAO] Loading pickle /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/train_data/preprocessed/2024-01-17_y_val_2019.pkl\n",
      "2024-01-17 21:01:59,155-INFO: [DataController] Fetched covariates_scaled. Min date: 2006-01-01 00:00:00 Max date: 2019-12-31 00:00:00\n",
      "2024-01-17 21:01:59,161-INFO: [DataController] Fetched y_train_scaled. Min date: 2006-01-01 00:00:00 Max date: 2018-12-31 00:00:00\n",
      "2024-01-17 21:01:59,163-INFO: [DataController] Fetched y_val. Min date: 2019-01-01 00:00:00 Max date: 2019-12-31 00:00:00\n",
      "2024-01-17 21:01:59,164-INFO: [ModelTrainer] Fitting model\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0     \n",
      "1  | val_metrics                       | MetricCollection                 | 0     \n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0     \n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 23.4 K\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 11.6 K\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 648   \n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 648   \n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 648   \n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 648   \n",
      "10 | lstm_encoder                      | LSTM                             | 3.7 K \n",
      "11 | lstm_decoder                      | LSTM                             | 3.7 K \n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 336   \n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 792   \n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 387   \n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 336   \n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 648   \n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 336   \n",
      "18 | output_layer                      | Linear                           | 221   \n",
      "----------------------------------------------------------------------------------------\n",
      "47.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.8 K    Total params\n",
      "0.191     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 126/126 [04:19<00:00,  0.48it/s, train_loss=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 126/126 [04:19<00:00,  0.48it/s, train_loss=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 21:06:20,041-INFO: [ModelTrainer] Forecasting with model\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 21:06:20,341-INFO: [ModelTrainer] Evaluating forecast\n",
      "2024-01-17 21:06:20,375-INFO: [ModelTrainer] Saving model outputs\n",
      "2024-01-17 21:06:20,376-INFO: [DatabaseDAO] Saving metrics to DB\n",
      "2024-01-17 21:06:20,387-INFO: [DatabaseDAO] Saving dataset to forecasts\n",
      "2024-01-17 21:06:20,396-INFO: [DataController] Saving model to /Users/francoferrero/Documents/Repos/xtream-fferrero/challenge_4/mock_storage/models/2_test_model_1_2024-01-17_2019.pt\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train(target_year,today,'test_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtream_main",
   "language": "python",
   "name": "xtream_main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
